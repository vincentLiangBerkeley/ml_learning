{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 213451 data points in training set.\n",
      "date_account_created        object\n",
      "timestamp_first_active       int64\n",
      "date_first_booking          object\n",
      "gender                      object\n",
      "age                        float64\n",
      "signup_method               object\n",
      "signup_flow                  int64\n",
      "language                    object\n",
      "affiliate_channel           object\n",
      "affiliate_provider          object\n",
      "first_affiliate_tracked     object\n",
      "signup_app                  object\n",
      "first_device_type           object\n",
      "first_browser               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train_users_2.csv')\n",
    "test = pd.read_csv('./test_users.csv')\n",
    "train.drop('id', axis=1, inplace=True)\n",
    "labels = train['country_destination'].values\n",
    "train.drop('country_destination', axis=1, inplace=True)\n",
    "print 'There are %d data points in training set.' % (train.shape[0])\n",
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning:\n",
    "## According to the data exploration notebook, there are a few steps we need to clean the data\n",
    "1. For age, we need to replace users with invalid age(too large or too small) with nan\n",
    "2. For gender, we need to replace unknown gender with nan\n",
    "3. For timestamp, we need to delete the data with NULL timestamp\n",
    "4. Convert categorical features to type \"category\"\n",
    "5. Convert date and time data to type \"date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'affiliate_channel', u'affiliate_provider', u'age',\n",
      "       u'date_account_created', u'date_first_booking',\n",
      "       u'first_affiliate_tracked', u'first_browser', u'first_device_type',\n",
      "       u'gender', u'language', u'signup_app', u'signup_flow', u'signup_method',\n",
      "       u'timestamp_first_active'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_index = train.shape[0]\n",
    "id_test = test['id']\n",
    "df_all = pd.concat((train, test), axis=0, ignore_index=True)\n",
    "df_all.drop(['id'], axis=1, inplace=True)\n",
    "print df_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat train and test data to do data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.loc[df_all['age']>95] = np.nan\n",
    "df_all.loc[df_all['age']<15] = np.nan\n",
    "df_all['gender'].replace('-unknown', np.nan, inplace=True)\n",
    "df_all = df_all.dropna(axis=0, how='all')\n",
    "categorical = ['affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'first_browser'\n",
    "              , 'first_device_type', 'gender', 'language', 'signup_app', 'signup_flow', 'signup_method']\n",
    "for cat in categorical:\n",
    "    df_all = pd.concat((df_all, pd.get_dummies(df_all[cat].astype('category'), prefix=cat)), axis=1)\n",
    "    df_all.drop([cat], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                   42.856567\n",
      "date_first_booking    67.892596\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now let us take a look at missing data\n",
    "df_null = df_all.isnull().sum() / df_all.shape[0] * 100\n",
    "print df_null[df_null>0]\n",
    "\n",
    "# Since more than half of the data for date_first_booking is missing, I will simply drop it\n",
    "df_all.drop(['date_first_booking'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date_created to year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_created = df_all['date_account_created'].apply(lambda x:x.split('-'))\n",
    "df_all['year_created'] = date_created.apply(lambda x: int(x[0]))\n",
    "df_all['month_created'] = date_created.apply(lambda x: int(x[1]))\n",
    "df_all['day_created'] = date_created.apply(lambda x: int(x[2]))\n",
    "df_all.drop(['date_account_created'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert time first active to year, month, day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_active = df_all['timestamp_first_active'].astype(int).astype(str).apply(lambda x:[x[0:4], x[4:6], x[6:8]])\n",
    "df_all['year_active'] = time_active.apply(lambda x:int(x[0]))\n",
    "df_all['month_active'] = time_active.apply(lambda x:int(x[1]))\n",
    "df_all['day_active'] = time_active.apply(lambda x:int(x[2]))\n",
    "df_all.drop(['timestamp_first_active'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill the nan age with -1\n",
    "df_all.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase : Model selection\n",
    "1. Split data into train and test subsets, using the data point count we had before;\n",
    "2. This is a multi-class classification problem, we can try DecisionTree, LogisticRegression and SVM to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "values = df_all.values\n",
    "X_train = values[:train_index]\n",
    "X_test = values[train_index:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement the ndcg measure used by Kaggle, here I used the hack for this problem that IDCG_k is 1 if the correct result\n",
    "# is in the predicted list and zero otherwise. \n",
    "from time import time\n",
    "def ndcg(y_true, y_pred, k=5):\n",
    "    ''' Normalized Discounted Cumulative Score.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    y_true : list, shape=[n_samples]\n",
    "             True class labels\n",
    "    y_pred : list, shape=[n_samples, n_classes]\n",
    "             Predicted probabilities\n",
    "    k : int\n",
    "        Number of probabilities to use\n",
    "    \n",
    "    Return\n",
    "    ---------\n",
    "    score: float\n",
    "           The mean NDCG score on the data set\n",
    "    '''\n",
    "    \n",
    "    def dcg(y_true, y_pred, k=5):\n",
    "        order = sorted(range(len(y_pred)), key=lambda k:y_pred[k], reverse=True)\n",
    "        # Assume the classed are dictinct\n",
    "        for i in range(1,k+1):\n",
    "            if order[i-1] == y_true:\n",
    "                return 1/np.log2(i+1)\n",
    "        return 0\n",
    "    \n",
    "    score = []\n",
    "    for i in range(len(y_true)):\n",
    "        score.append(dcg(y_true[i], y_pred[i], k))\n",
    "    return np.mean(score)\n",
    "\n",
    "def train_predict(X_train, y, X_test, y_test, clf):\n",
    "    start = time()\n",
    "    clf.fit(X_train, y)\n",
    "    end = time()\n",
    "    train_time = end - start\n",
    "      \n",
    "    pred = clf.predict_proba(X_train)\n",
    "    score = ndcg(y, pred)\n",
    "    \n",
    "    start = time()\n",
    "    pred_test = clf.predict_proba(X_test)\n",
    "    end = time()\n",
    "    predict_time = end - start\n",
    "    \n",
    "    score_test = ndcg(y_test, pred_test)\n",
    "    print \"Trained model %s on %d data points in %.4f seconds.\" % (clf.__class__.__name__,X_train.shape[0],train_time)\n",
    "    print \"Predicted on the training set in %.4f seconds.\" % (predict_time)\n",
    "    print \"The score on the training set is %.4f and that on the test set is %.4f\" % (score, score_test)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data set with increasing size for comparison among the classifiers\n",
    "size = X_train.shape[0]/4\n",
    "\n",
    "train_1 = X_train[0:size]\n",
    "test_1 = y[0:size]\n",
    "train_2 = X_train[0:size*2]\n",
    "test_2 = y[0:size*2]\n",
    "train_3 = X_train[0:size*3]\n",
    "test_3 = y[0:size*3]\n",
    "\n",
    "test_X = X_train[size*3:]\n",
    "test_y = y[size*3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the classifiers for experiment\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "RAND_SEED = 0\n",
    "dtclf = DecisionTreeClassifier(min_samples_split=20, random_state=RAND_SEED)\n",
    "lrclf = LogisticRegression()\n",
    "nbclf = MultinomialNB()\n",
    "clfs = [dtclf, lrclf, nbclf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model DecisionTreeClassifier on 53362 data points in 0.6148 seconds.\n",
      "Predicted on the training set in 0.0337 seconds.\n",
      "The score on the training set is 0.8596 and that on the test set is 0.6507\n",
      "\n",
      "\n",
      "Trained model DecisionTreeClassifier on 106724 data points in 2.2828 seconds.\n",
      "Predicted on the training set in 0.0362 seconds.\n",
      "The score on the training set is 0.8607 and that on the test set is 0.6905\n",
      "\n",
      "\n",
      "Trained model DecisionTreeClassifier on 160086 data points in 2.2978 seconds.\n",
      "Predicted on the training set in 0.0428 seconds.\n",
      "The score on the training set is 0.8666 and that on the test set is 0.7078\n",
      "\n",
      "\n",
      "Trained model LogisticRegression on 53362 data points in 6.4993 seconds.\n",
      "Predicted on the training set in 0.0870 seconds.\n",
      "The score on the training set is 0.7758 and that on the test set is 0.8221\n",
      "\n",
      "\n",
      "Trained model LogisticRegression on 106724 data points in 9.5587 seconds.\n",
      "Predicted on the training set in 0.0938 seconds.\n",
      "The score on the training set is 0.7873 and that on the test set is 0.8223\n",
      "\n",
      "\n",
      "Trained model LogisticRegression on 160086 data points in 13.2305 seconds.\n",
      "Predicted on the training set in 0.1632 seconds.\n",
      "The score on the training set is 0.8016 and that on the test set is 0.8223\n",
      "\n",
      "\n",
      "Trained model MultinomialNB on 53362 data points in 0.0779 seconds.\n",
      "Predicted on the training set in 0.0789 seconds.\n",
      "The score on the training set is 0.7607 and that on the test set is 0.6616\n",
      "\n",
      "\n",
      "Trained model MultinomialNB on 106724 data points in 0.1998 seconds.\n",
      "Predicted on the training set in 0.1644 seconds.\n",
      "The score on the training set is 0.7813 and that on the test set is 0.8062\n",
      "\n",
      "\n",
      "Trained model MultinomialNB on 160086 data points in 0.5288 seconds.\n",
      "Predicted on the training set in 0.1133 seconds.\n",
      "The score on the training set is 0.7945 and that on the test set is 0.8091\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    train_predict(train_1, test_1, test_X, test_y, clf)\n",
    "    train_predict(train_2, test_2, test_X, test_y, clf)\n",
    "    train_predict(train_3, test_3, test_X, test_y, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classifier 1: Decision Tree **\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | NDCG (train)| NDCG (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 53362             |  0.6148                 |   0.0337               | 0.8596           |  0.6507         |\n",
    "| 106724            |  2.2828                 |   0.0362               | 0.8607           |  0.6905         |\n",
    "| 160086            |  2.2978                 |   0.0428               | 0.7873           |  0.8223         |\n",
    "\n",
    "** Classifier 2: Logistic Regression **\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | NDCG (train)| NDCG (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 53362             |  6.4993                 |   0.0870               | 0.7758           |  0.8221         |\n",
    "| 106724            |  9.5587                 |   0.0938               | 0.7873           |  0.8223         |\n",
    "| 160086            |  13.2305                |   0.1632               | 0.8016           |  0.8223         |\n",
    "\n",
    "** Classifier 3: Multinomial Naive Bayes **\n",
    "\n",
    "| Training Set Size | Training Time | Prediction Time (test) | NDCG (train)| NDCG (test) |\n",
    "| :---------------: | :---------------------: | :--------------------: | :--------------: | :-------------: |\n",
    "| 53362             |  0.0779                 |   0.0789               | 0.7607           |  0.6616         |\n",
    "| 106724            |  0.1998                 |   0.1644               | 0.7813           |  0.8062         |\n",
    "| 160086            |  0.5288                 |   0.1133               | 0.7945           |  0.8091         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training phase: Cross validation\n",
    "As we can see that when training on the whole data set, DecisionTree is a better model in training time, and NDCG on the test set, so I will dig deeper into DecisionTree by cross-validation on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(n=X_train.shape[0], n_folds=4)\n",
    "params = {'criterion': ['gini', 'entropy'], 'min_samples_split':[50, 100, 150, 200, 250]}\n",
    "clf = DecisionTreeClassifier(random_state=RAND_SEED)\n",
    "ndcg_scorer = make_scorer(ndcg, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_samples_split': [50, 100, 150, 200, 250], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True,\n",
       "       scoring=make_scorer(ndcg, needs_proba=True), verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(clf, params, ndcg_scorer)\n",
    "grid.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=200, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=0, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "best = grid.best_estimator_\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = best.predict_proba(X_train)\n",
    "score = ndcg(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816928123685\n"
     ]
    }
   ],
   "source": [
    "print score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase: Ensemble learning\n",
    "1. Random forest classifier\n",
    "2. Ada boosted tree\n",
    "3. Gradient boosted tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "rfclf = RandomForestClassifier(criterion='entropy', min_samples_split=20, random_state=RAND_SEED, class_weight='balanced')\n",
    "adclf = AdaBoostClassifier(base_estimator=best, random_state=RAND_SEED)\n",
    "xgclf = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25, objective='multi:softprob', subsample=0.5, \n",
    "                     colsample_bytree=0.5, seed=RAND_SEED)\n",
    "eclfs = [rfclf, adclf, xgclf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model RandomForestClassifier on 53362 data points in 0.7124 seconds.\n",
      "Predicted on the training set in 0.1468 seconds.\n",
      "The score on the training set is 0.7614 and that on the test set is 0.5895\n",
      "\n",
      "\n",
      "Trained model RandomForestClassifier on 106724 data points in 1.5294 seconds.\n",
      "Predicted on the training set in 0.1748 seconds.\n",
      "The score on the training set is 0.7582 and that on the test set is 0.6114\n",
      "\n",
      "\n",
      "Trained model RandomForestClassifier on 160086 data points in 2.7595 seconds.\n",
      "Predicted on the training set in 0.1866 seconds.\n",
      "The score on the training set is 0.7654 and that on the test set is 0.6482\n",
      "\n",
      "\n",
      "Trained model AdaBoostClassifier on 53362 data points in 22.5017 seconds.\n",
      "Predicted on the training set in 1.5054 seconds.\n",
      "The score on the training set is 0.8060 and that on the test set is 0.7551\n",
      "\n",
      "\n",
      "Trained model AdaBoostClassifier on 106724 data points in 58.8780 seconds.\n",
      "Predicted on the training set in 1.4139 seconds.\n",
      "The score on the training set is 0.8048 and that on the test set is 0.7612\n",
      "\n",
      "\n",
      "Trained model AdaBoostClassifier on 160086 data points in 100.9377 seconds.\n",
      "Predicted on the training set in 1.5827 seconds.\n",
      "The score on the training set is 0.8092 and that on the test set is 0.7646\n",
      "\n",
      "\n",
      "Trained model XGBClassifier on 53362 data points in 93.1085 seconds.\n",
      "Predicted on the training set in 1.5178 seconds.\n",
      "The score on the training set is 0.7913 and that on the test set is 0.7599\n",
      "\n",
      "\n",
      "Trained model XGBClassifier on 106724 data points in 225.9417 seconds.\n",
      "Predicted on the training set in 1.4754 seconds.\n",
      "The score on the training set is 0.7954 and that on the test set is 0.8197\n",
      "\n",
      "\n",
      "Trained model XGBClassifier on 160086 data points in 317.6112 seconds.\n",
      "Predicted on the training set in 1.5276 seconds.\n",
      "The score on the training set is 0.8068 and that on the test set is 0.8216\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in eclfs:\n",
    "    train_predict(train_1, test_1, test_X, test_y, clf)\n",
    "    train_predict(train_2, test_2, test_X, test_y, clf)\n",
    "    train_predict(train_3, test_3, test_X, test_y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate submission file\n",
    "y_pred = xgclf.predict_proba(X_test)\n",
    "ids = []\n",
    "pred = []\n",
    "for i in range(len(y_pred)):\n",
    "    ids += [id_test[i]] * 5\n",
    "    order = sorted(range(len(y_pred[i])), key=lambda k:y_pred[i][k], reverse=True)\n",
    "    pred += le.inverse_transform(order[:5]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.column_stack((ids, pred)), columns=['id', 'country'])\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
